# -*- coding: utf-8 -*-
"""train_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VG5VsXaAz9sykJoeoYmVVXwAvRzqyyn3

# **Artist_Style_Identification - Train**
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive

# Montar Google Drive
drive.mount('/content/drive')

# %cd "/content/drive/MyDrive/ArtisticStyle/"
!ls

import os
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger
from sklearn.metrics import confusion_matrix, classification_report

# Directorios de entrenamiento y validación
base_dir = 'dataset_v1'
train_dir = os.path.join(base_dir,'train')
val_dir = os.path.join(base_dir, 'validation')

# Configuración del generador de aumento de datos
train_datagen = ImageDataGenerator(
    rescale=1./255, # Escalamiento: Ajustar valores de píxeles a [0, 1]
    rotation_range=20,
    # width_shift_range=0.2,
    # height_shift_range=0.2,
    # zoom_range=0.2,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(rescale=1./255)

# Carga de imágenes [Aumento de datos: Generar nuevas imágenes]
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224), # Redimensionamiento: Ajustar a tamaño específico
    batch_size=32,
    class_mode='binary'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# Visualización de imágenes procesadas
images, labels = next(train_generator)

plt.figure(figsize=(12, 12))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(images[i])
    plt.title(f'Label: {labels[i]}')
    plt.axis('off')

plt.show()

# Creación del modelo original
# base_model = ResNet50(weights='imagenet', include_top=False)
# base_model.trainable = False

# Añadir capas personalizadas
# model = tf.keras.Sequential()
# model.add(base_model)
# model.add(GlobalAveragePooling2D())
# model.add(Dense(512, activation='relu'))
# model.add(Dense(1, activation='sigmoid'))

# Compilar el modelo
# model.compile(loss='binary_crossentropy',
#               optimizer=Adam(learning_rate=1e-3),
#               metrics=['acc'])

# Mostrar el resumen del modelo
# model.summary()

# Entrenar el modelo original
# history = model.fit(
#     train_generator,
#     epochs=10,
#     validation_data=val_generator
# )

# acc = history.history['acc']
# loss = history.history['loss']

# Guardar el modelo original
# model.save('artist_style_base_model.keras')

# Cargar el modelo guardado para continuar el entrenamiento
model = load_model('artist_style_base_model.keras')

# Crear un callback para guardar el mejor modelo
checkpoint_callback = ModelCheckpoint('artist_style_model_{epoch:02d}.keras',
                                      save_best_only=True,
                                      monitor='val_accuracy',
                                      mode='max')

# Crear callback para guardar el modelo al final del entrenamiento
final_model_checkpoint = ModelCheckpoint('artist_style_model_final.keras',
                                         save_weights_only=False,
                                         verbose=1)

csv_logger = CSVLogger('training.log')

# Continuar entrenando el modelo cargado con más épocas
history = model.fit(
    train_generator,
    epochs=20,
    validation_data=val_generator,
    callbacks=[checkpoint_callback, final_model_checkpoint, csv_logger]
)

acc = history.history['acc']
loss = history.history['loss']

# Mostrar gráficas de loss y accuracy
epochs = range(1, len(acc)+1)

plt.figure()
#subplot(r,c) provide the no. of rows and columns
f, axarr = plt.subplots(1, 2, figsize=(10, 3))
axarr[0].plot(epochs,acc,label='train accuracy')
axarr[0].legend()
axarr[1].plot(epochs,loss,label='train loss')
axarr[1].legend()

# Predecir las clases para el conjunto de entrenamiento
train_pred = model.predict(train_generator)
train_pred_classes = np.round(train_pred)

# Calcular la matriz de confusión
conf_matrix = confusion_matrix(train_generator.classes, train_pred_classes)

# Visualizar la matriz de confusión con seaborn
print("\nMatriz de confusión (Entrenamiento):\n")
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Artista', 'Artista'],
            yticklabels=['No Artista', 'Artista'])
plt.title('Matriz de Confusión (Entrenamiento)')
plt.xlabel('Predicciones')
plt.ylabel('Valores Reales')
plt.show()

# Calcular las métricas
report = classification_report(train_generator.classes, train_pred_classes, target_names=train_generator.class_indices)

# Mostrar el reporte de clasificación
print("\nReporte de clasificación (Entrenamiento):\n", report)

# Calcular el accuracy para el conjunto de prueba
train_loss, train_accuracy = model.evaluate(train_generator)
print(f"Accuracy en entrenamiento: {train_accuracy * 100:.2f}%")
print("Pérdida durante el entrenamiento:", test_loss)