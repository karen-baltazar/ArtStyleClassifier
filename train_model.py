# -*- coding: utf-8 -*-
"""train_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VG5VsXaAz9sykJoeoYmVVXwAvRzqyyn3

# **Artist_Style_Identification - Train**
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive

# Montar Google Drive
drive.mount('/content/drive')

# %cd "/content/drive/MyDrive/ArtisticStyle/"
!ls

import os
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.layers import Dropout
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger
from tensorflow.keras.models import load_model
from sklearn.metrics import confusion_matrix, classification_report

# Directorios de entrenamiento y validación
base_dir = 'dataset_v2'
train_dir = os.path.join(base_dir,'train')
val_dir = os.path.join(base_dir, 'validation')

# Configuración del generador de aumento de datos
train_datagen = ImageDataGenerator(
    rescale=1./255, # Escalamiento: Ajustar valores de píxeles a [0, 1]
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

# Carga de imágenes [Aumento de datos: Generar nuevas imágenes]
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224), # Redimensionamiento: Ajustar a tamaño específico
    batch_size=32,
    class_mode='binary'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# Visualización de imágenes procesadas
images, labels = next(train_generator)

plt.figure(figsize=(12, 12))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(images[i])
    plt.title(f'Label: {labels[i]}')
    plt.axis('off')

plt.show()

# Creación del modelo original
base_model = ResNet50(weights='imagenet', include_top=False)
base_model.trainable = False

# Añadir capas personalizadas
model = tf.keras.Sequential()
model.add(base_model)
model.add(GlobalAveragePooling2D())
model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

# Compilar el modelo
model.compile(loss='binary_crossentropy',
              optimizer=Adam(learning_rate=1e-3),
              metrics=['acc'])

# Mostrar el resumen del modelo
model.summary()

# Crear un callback para guardar el mejor modelo
best_model_callback = ModelCheckpoint('best_artist_style_model.keras',
                                      save_best_only=True,
                                      monitor='val_acc',
                                      mode='max')

# Crear callback para guardar el modelo al final del entrenamiento
updated_model_checkpoint = ModelCheckpoint('updated_artist_style_model.keras',
                                         save_weights_only=False,
                                         verbose=1)

csv_logger = CSVLogger('training.log')

# Entrenar el modelo
history = model.fit(
    train_generator,
    epochs=20,
    validation_data=val_generator,
    callbacks=[best_model_callback, updated_model_checkpoint, csv_logger]
)

acc = history.history['acc']
loss = history.history['loss']

# Mostrar gráficas de loss y accuracy
epochs = range(1, len(acc)+1)

plt.figure()
#subplot(r,c) provide the no. of rows and columns
f, axarr = plt.subplots(1, 2, figsize=(10, 3))
axarr[0].plot(epochs,acc,label='train accuracy')
axarr[0].legend()
axarr[1].plot(epochs,loss,label='train loss')
axarr[1].legend()

# Cargar el modelo guardado
model_path = 'best_artist_style_model.keras' # Cambiar según sea necesario
model = load_model(model_path)

# Predecir las clases para el conjunto de entrenamiento
train_pred = model.predict(train_generator)
train_pred_classes = np.round(train_pred)

# Calcular la matriz de confusión
conf_matrix = confusion_matrix(train_generator.classes, train_pred_classes)

# Visualizar la matriz de confusión con seaborn
print("\nMatriz de confusión (Entrenamiento):\n")
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Artista', 'Artista'],
            yticklabels=['No Artista', 'Artista'])
plt.title('Matriz de Confusión (Entrenamiento)')
plt.xlabel('Predicciones')
plt.ylabel('Valores Reales')
plt.show()

# Calcular las métricas
report = classification_report(train_generator.classes, train_pred_classes, target_names=train_generator.class_indices)

# Mostrar el reporte de clasificación
print("\nReporte de clasificación (Entrenamiento):\n", report)

# Calcular el accuracy para el conjunto de prueba
train_loss, train_accuracy = model.evaluate(train_generator)
print(f"Accuracy en entrenamiento: {train_accuracy * 100:.2f}%")
print("Pérdida durante el entrenamiento:", train_loss)